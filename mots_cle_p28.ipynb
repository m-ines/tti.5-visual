{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dc2c3fe-9299-42dc-aa08-12714b2f1212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Étiquette  Nombre_de_récurrence\n",
      "0                                      0                 67495\n",
      "1                      electric vehicles                  2675\n",
      "2                        electrification                  1253\n",
      "3                       electric vehicle                   558\n",
      "4              battery electric vehicles                   437\n",
      "...                                  ...                   ...\n",
      "23195          trolleybus infrastructure                     1\n",
      "23196  electrified public transportation                     1\n",
      "23197                       static model                     1\n",
      "23198                   computation time                     1\n",
      "23199       bidirectional direct current                     1\n",
      "\n",
      "[23200 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#2. Relier les bulles connectées entre elles \n",
    "\n",
    "import dash\n",
    "from dash import html, dcc, Input, Output\n",
    "import plotly.graph_objects as go\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "### Etude du fichier csv et compte des étiquettes \n",
    "\n",
    "df = pd.read_csv(\"Data_20250506.csv\", sep=';')\n",
    "\n",
    "etiquettes_data = df.iloc[:, 11:]  # à partir de la colonne 12, on prend tous les mots clés des études scientifiques \n",
    "etiquettes_series = pd.Series(etiquettes_data.values.ravel())\n",
    "\n",
    "# Nettoyage des valeurs : on enlève les cases vides, les majuscules...car sinon on compterait différemment Fer et fer par exemple\n",
    "\n",
    "etiquettes_series = etiquettes_series.dropna().astype(str).str.strip().str.lower() \n",
    "\n",
    "etiquettes_comptes = etiquettes_series.value_counts().reset_index()  # compte le nombre d'occurences dans toute la littérature scientifique\n",
    "etiquettes_comptes.columns = ['Étiquette', 'Nombre_de_récurrence']\n",
    "\n",
    "print(etiquettes_comptes)\n",
    "\n",
    "\n",
    "\n",
    "#### A ce point la, certains mots sont encore compté deux fois différement  = electric vehicles et elecric vehicle par exmple !\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9acfb48c-95af-4a3a-9277-5c81338445ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/heloisecouet/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/heloisecouet/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenise \n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78a48ac7-9588-4dfc-b1c8-d609f64bcdbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Electric vehicles have been developed with the aims of saving energy and reducing carbon dioxide emissions. Furthermore, as a single bus can transport many people, buses produce low carbon dioxide emissions per person in comparison with cars. In recent years, community buses have been introduced to ensure the mobility of senior citizens. Therefore, a low-floor vehicle was adopted as the base vehicle in our latest project. The bus was demonstrated around the center of the city. It followed a circular route of distance 7.2 kilometers, the number of bus stops on the route was 27 and the driving time was 40 minutes per circuit. This demonstration was repeated three to four times a day for 14 days. During the 86 circuits of the demonstration, a total of 1,110 passengers used the bus and the total running distance was 776 kilometers. From these results, we concluded that the quantity of carbon dioxide emissions could be reduced by 37% using our proposed bus in comparison with that of a conventional diesel-engine bus.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "text=df['AB_AI'][0]\n",
    "print(text)\n",
    "\n",
    "tokens = word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bb61601-2438-4595-974e-9912bd5d481e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nombre de mots de text : 1026\n",
      "nombre de mots de words : 187\n",
      "nombre de mots de W ( sans ponctuation) : 88\n",
      "nombre de mots de W_sans_ED : 78\n",
      "['citizens', 'quantity', 'circuit', 'This', '86', 'project', 'Electric', 'comparison', 'saving', 'senior', 'recent', 'The', 'city', '40', '14', 'times', 'During', 'emissions', 'ensure', 'kilometers', 'aims', 'circular', 'minutes', 'dioxide', 'It', 'bus', 'using', 'stops', 'three', 'diesel-engine', 'route', 'transport', 'days', 'From', 'reducing', 'cars', 'many', 'circuits', 'people', 'vehicle', 'time', 'base', 'four', 'low', 'per', 'number', 'carbon', 'distance', 'center', 'produce', 'day', 'energy', 'low-floor', 'single', 'years', 'person', 'community', '7.2', '776', '1,110', 'running', 'results', '37', '27', 'vehicles', 'Furthermore', 'could', 'passengers', 'mobility', 'In', 'around', 'Therefore', 'demonstration', 'conventional', 'driving', 'buses', 'latest', 'total']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/heloisecouet/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Virons les stop words \n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stopwords = set(stopwords.words('english'))\n",
    "print('nombre de mots de text :' , len(text))\n",
    "words = word_tokenize(text)\n",
    "words_filtered = []\n",
    "print('nombre de mots de words :' , len(words))\n",
    "# on va renvoyer une liste des mots en ne gardant \"que les plus importants\". On enlève par exemple les \"is\", \"of... En somme, on ne garde que les mots clés.\n",
    "for w in words:\n",
    "  if w not in stopwords:\n",
    "    words_filtered.append(w)\n",
    "\n",
    "\n",
    "\n",
    "# J'enlève maintenant toute la ponctuation de ma liste de mots. \n",
    "ponctuation = ['.',',',';','?',':','!','%']\n",
    "words_sans_ponctuation=[x for x in words_filtered if x not in ponctuation]\n",
    "\n",
    "\n",
    "# on a beaucoup de doublons dans la liste : on les retire pour diminuer le nombre de mots \n",
    "W=list(set(words_sans_ponctuation))\n",
    "print('nombre de mots de W ( sans ponctuation) :' , len(W))\n",
    "# on fait un choix : on enlève les mots qui terminent par \"ED\" en anglais car on estime que ce sont des verbes, et non les principaux mots-clés. \n",
    "\n",
    "\n",
    "W_sans_ED = [w for w in W if not w.lower().endswith(\"ed\")] \n",
    "print('nombre de mots de W_sans_ED :' , len(W_sans_ED))\n",
    "print(W_sans_ED)\n",
    "\n",
    "# A ce stade on a réussi à réduire le nombre de mots clés de 1026 mots à 79. Ca rste encore beaucoup trop si on veut traiter beaucoup d'articles en meme temps. \n",
    "sans_maj = [w.lower() for w in W_sans_ED]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74bca924-39b4-4fb3-bddb-faafcd98466e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nombre de mots de mots_filtrés : 72\n",
      "['citizens', 'quantity', 'circuit', '86', 'project', 'electric', 'comparison', 'saving', 'senior', 'recent', 'city', '40', '14', 'times', 'emissions', 'ensure', 'kilometers', 'aims', 'circular', 'minutes', 'dioxide', 'bus', 'using', 'stops', 'three', 'diesel-engine', 'route', 'transport', 'days', 'reducing', 'cars', 'many', 'circuits', 'people', 'vehicle', 'time', 'base', 'four', 'low', 'per', 'number', 'carbon', 'distance', 'center', 'produce', 'day', 'energy', 'low-floor', 'single', 'years', 'person', 'community', '7.2', '776', '1,110', 'running', 'results', '37', '27', 'vehicles', 'furthermore', 'could', 'passengers', 'mobility', 'around', 'therefore', 'demonstration', 'conventional', 'driving', 'buses', 'latest', 'total']\n"
     ]
    }
   ],
   "source": [
    "# on enlève les majuscules pour pouvoir enlever les stopwords qui contenaient des majuscules \n",
    "mots_filtrés =[]\n",
    "for w in sans_maj:\n",
    "  if w not in stopwords:\n",
    "    mots_filtrés.append(w)\n",
    "\n",
    "print('nombre de mots de mots_filtrés :' , len(mots_filtrés))\n",
    "print(mots_filtrés)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b68aa35b-c6f4-4045-a204-48c4a5db61a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nombre de mots de W_singuliers 67\n",
      "['776', 'ensure', 'quantity', '1,110', 'running', 'people', 'circuit', 'citizen', 'aim', 'therefore', '86', 'project', 'emission', 'minute', 'vehicle', 'time', 'base', 'year', 'circular', 'four', 'comparison', 'saving', 'senior', 'dioxide', '37', 'recent', '27', 'low', 'bus', 'using', 'city', 'could', 'per', '40', 'number', 'carbon', 'three', 'distance', 'center', 'day', 'produce', '14', 'mobility', 'energy', 'around', 'diesel-engine', 'low-floor', 'single', 'electric', 'route', 'transport', 'demonstration', 'stop', 'conventional', 'person', 'passenger', 'result', 'driving', 'community', 'latest', 'reducing', 'kilometer', '7.2', 'total', 'furthermore', 'many', 'car']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/heloisecouet/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/heloisecouet/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Mise au singulier\n",
    "W_singuliers = list(set([lemmatizer.lemmatize(w, pos='n') for w in mots_filtrés]))\n",
    "\n",
    "print('nombre de mots de W_singuliers', len(W_singuliers))\n",
    "print(W_singuliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f932361-a023-4f5f-a293-ebffa255639b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nombre de mots de mots_assez_long 62\n",
      "['776', 'ensure', 'quantity', '1,110', 'running', 'people', 'circuit', 'citizen', 'aim', 'therefore', 'project', 'emission', 'minute', 'vehicle', 'time', 'base', 'year', 'circular', 'four', 'comparison', 'saving', 'senior', 'dioxide', 'recent', 'low', 'bus', 'using', 'city', 'could', 'per', 'number', 'carbon', 'three', 'distance', 'center', 'day', 'produce', 'mobility', 'energy', 'around', 'diesel-engine', 'low-floor', 'single', 'electric', 'route', 'transport', 'demonstration', 'stop', 'conventional', 'person', 'passenger', 'result', 'driving', 'community', 'latest', 'reducing', 'kilometer', '7.2', 'total', 'furthermore', 'many', 'car']\n"
     ]
    }
   ],
   "source": [
    "# j'enlève les mots de moins de 3 caractères ; \n",
    "mots_assez_long = []\n",
    "for w in W_singuliers : \n",
    "    if len(w)>=3 : \n",
    "        mots_assez_long.append(w)\n",
    "\n",
    "print('nombre de mots de mots_assez_long', len(mots_assez_long))\n",
    "print(mots_assez_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f304b5e3-3d1a-4f2a-a5bd-c600c9655ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nombre de mots de W_sans_nombres 59\n",
      "['ensure', 'quantity', 'running', 'people', 'circuit', 'citizen', 'aim', 'therefore', 'project', 'emission', 'minute', 'vehicle', 'time', 'base', 'year', 'circular', 'four', 'comparison', 'saving', 'senior', 'dioxide', 'recent', 'low', 'bus', 'using', 'city', 'could', 'per', 'number', 'carbon', 'three', 'distance', 'center', 'day', 'produce', 'mobility', 'energy', 'around', 'diesel-engine', 'low-floor', 'single', 'electric', 'route', 'transport', 'demonstration', 'stop', 'conventional', 'person', 'passenger', 'result', 'driving', 'community', 'latest', 'reducing', 'kilometer', 'total', 'furthermore', 'many', 'car']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def est_nombre(w):\n",
    "    return re.fullmatch(r\"[0-9]+([.,][0-9]+)?\", w) is not None\n",
    "\n",
    "W_sans_nombres = [w for w in mots_assez_long if not est_nombre(w)]\n",
    "\n",
    "print('nombre de mots de W_sans_nombres', len(W_sans_nombres))\n",
    "print(W_sans_nombres)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2aa8e0-007a-4827-8408-d51dfaaf2f5a",
   "metadata": {},
   "source": [
    "On a réussi à passer de 1026 mots à 59 ! Il me faudrait maintenant une IA pour enlever les mots ayant moins d'intéret en fonction du sujet pour sélectionner les mots clé importants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8174ba8d-a792-43a9-a1dc-4069d4445431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7100\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(len(df['AB_AI']))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd6c4527-3b5e-4c32-8e3d-ebdb269c9629",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/heloisecouet/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/heloisecouet/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/heloisecouet/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Faisons une fonction plus rapide pour sélectionner les mots importants d'un titre d'article : \n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "import re\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stopwords = set(stopwords.words('english'))\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "def est_nombre(w):\n",
    "        return re.fullmatch(r\"[0-9]+([.,][0-9]+)?\", w) is not None\n",
    "\n",
    "\n",
    "def mots_cles(text) : \n",
    "\n",
    "\n",
    "    words = word_tokenize(text)\n",
    "    sans_maj = [w.lower() for w in words]\n",
    "    words_filtered = []\n",
    "    for w in sans_maj:\n",
    "      if w not in stopwords:\n",
    "        words_filtered.append(w)\n",
    "\n",
    "\n",
    "#ponctuation \n",
    "    ponctuation = ['.',',',';','?',':','!','%']\n",
    "    words_sans_ponctuation=[x for x in words_filtered if x not in ponctuation]\n",
    "\n",
    "\n",
    "# doublons\n",
    "    W=list(set(words_sans_ponctuation))\n",
    "\n",
    "# sans les -ED\n",
    "    W_sans_ED = [w for w in W if not w.lower().endswith(\"ed\")] \n",
    "\n",
    "# singulier\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    W_singuliers = list(set([lemmatizer.lemmatize(w, pos='n') for w in W_sans_ED]))\n",
    "\n",
    "#sans les mots très courts\n",
    "    mots_assez_long = []\n",
    "    for w in W_singuliers : \n",
    "        if len(w)>=3 : \n",
    "            mots_assez_long.append(w)\n",
    "\n",
    "# sans les nombres \n",
    "   \n",
    "    W_sans_nombres = [w for w in mots_assez_long if not est_nombre(w)]\n",
    "\n",
    "    return(W_sans_nombres)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "12a8e23c-9b88-4d38-b51f-a9332de71b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nombre de mots dans liste : 570063\n",
      "nombre de mots dans phrase :  18248\n"
     ]
    }
   ],
   "source": [
    "L = []\n",
    "\n",
    "#On vai maintenant parcourir tous les titres !\n",
    "for i in range (len(df['AB_AI'])) : \n",
    "    L.append(mots_cles(df['AB_AI'][i]))\n",
    "\n",
    "\n",
    "liste = [mot for sous_liste in L for mot in sous_liste]\n",
    "print('nombre de mots dans liste :',len(liste))  \n",
    "phrase = ' '.join(liste)\n",
    "\n",
    "print('nombre de mots dans phrase : ',len(mots_cles(phrase))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0734632b-7390-4583-96a8-03d120c3987f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "# Je range dans un dictionnaire le mot et son nombre d'apparition dans l'ensemble des titres, et ce par ordre décroissant d'apparition.\n",
    "compteur = Counter(liste)\n",
    "dico_trie = dict(compteur.most_common())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3c77cca1-af8c-40c2-adce-9b89d5e09310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On a réduit le nombre total de \"mots-clés\" de : 570063 à  234\n",
      "{'electric': 5740, 'vehicle': 5629, 'result': 3733, 'energy': 3708, 'system': 3624, 'study': 3278, 'model': 3164, 'paper': 3099, 'battery': 2693, 'charging': 2587, 'power': 2513, 'transport': 2298, 'using': 2278, 'electrification': 2077, 'different': 2068, 'emission': 2042, 'cost': 2026, 'also': 1998, 'show': 1981, 'analysis': 1940, 'however': 1855, 'impact': 1845, 'demand': 1806, 'technology': 1711, 'method': 1708, 'strategy': 1635, 'time': 1633, 'potential': 1578, 'performance': 1578, 'approach': 1546, 'data': 1524, 'use': 1479, 'fuel': 1471, 'increase': 1459, 'simulation': 1411, 'due': 1408, 'electricity': 1405, 'present': 1402, 'current': 1389, 'significant': 1387, 'high': 1379, 'carbon': 1376, 'reduce': 1364, 'network': 1310, 'sector': 1301, 'new': 1298, 'transportation': 1294, 'case': 1292, 'two': 1289, 'research': 1285, 'solution': 1282, 'scenario': 1260, 'operation': 1244, 'one': 1243, 'consumption': 1242, 'optimization': 1241, 'grid': 1230, 'efficiency': 1225, 'future': 1214, 'infrastructure': 1205, 'problem': 1182, 'development': 1172, 'environmental': 1171, 'challenge': 1156, 'management': 1152, 'effect': 1143, 'reduction': 1133, 'optimal': 1131, 'range': 1126, 'hybrid': 1119, 'renewable': 1110, 'level': 1109, 'policy': 1100, 'driving': 1091, 'condition': 1087, 'including': 1084, 'source': 1069, 'algorithm': 1069, 'load': 1063, 'control': 1061, 'change': 1047, 'station': 1043, 'gas': 1029, 'considering': 1025, 'capacity': 1020, 'factor': 1017, 'various': 1009, 'market': 999, 'provide': 986, 'design': 978, 'storage': 978, 'distribution': 973, 'well': 959, 'process': 940, 'dynamic': 934, 'application': 917, 'total': 913, 'number': 893, 'benefit': 888, 'could': 884, 'work': 881, 'generation': 874, 'charge': 871, 'area': 870, 'economic': 863, 'increasing': 862, 'important': 858, 'adoption': 846, 'framework': 844, 'aim': 842, 'conventional': 827, 'significantly': 825, 'three': 822, 'year': 819, 'fleet': 819, 'public': 818, 'first': 815, 'urban': 812, 'dioxide': 809, 'greenhouse': 801, 'issue': 800, 'per': 793, 'sustainable': 792, 'higher': 789, 'low': 788, 'parameter': 781, 'rate': 779, 'achieve': 777, 'global': 775, 'may': 774, 'finally': 763, 'behavior': 760, 'transition': 760, 'key': 759, 'region': 756, 'therefore': 746, 'finding': 744, 'within': 743, 'term': 741, 'state': 739, 'existing': 734, 'type': 731, 'mobility': 725, 'furthermore': 723, 'road': 722, 'cycle': 721, 'improve': 713, 'supply': 712, 'role': 712, 'characteristic': 704, 'novel': 700, 'service': 699, 'address': 697, 'main': 690, 'lower': 689, 'addition': 684, 'reducing': 679, 'value': 679, 'engine': 677, 'large': 674, 'price': 674, 'operating': 664, 'focus': 664, 'provides': 662, 'order': 659, 'proposes': 659, 'support': 657, 'test': 656, 'climate': 654, 'temperature': 647, 'several': 636, 'cell': 635, 'alternative': 633, 'planning': 630, 'internal': 628, 'modeling': 626, 'efficient': 621, 'mode': 619, 'industry': 618, 'air': 615, 'objective': 609, 'combustion': 608, 'environment': 605, 'production': 602, 'demonstrate': 598, 'moreover': 591, 'effective': 591, 'indicate': 590, 'without': 582, 'specific': 581, 'overall': 578, 'thus': 577, 'voltage': 576, 'resource': 575, 'influence': 570, 'among': 565, 'user': 564, 'respectively': 564, 'integration': 559, 'peak': 558, 'set': 556, 'many': 553, 'uncertainty': 551, 'direct': 549, 'less': 548, 'local': 545, 'electrical': 545, 'lead': 543, 'major': 539, 'bus': 538, 'available': 538, 'towards': 537, 'requirement': 534, 'effectiveness': 533, 'component': 532, 'plug-in': 529, 'better': 523, 'found': 517, 'target': 516, 'average': 516, 'point': 515, 'thermal': 511, 'operational': 510, 'heat': 509, 'location': 508, 'decision': 507, 'literature': 506, 'context': 506, 'passenger': 505, 'life': 504, 'goal': 503, 'smart': 502, 'flow': 501, 'comprehensive': 500}\n"
     ]
    }
   ],
   "source": [
    "# Je supprime tous les mots qui apparaissent moins de 500 fois en supposant ainsi que ce sont des mots peu importants, que je n'avais pas pu supprimer avant.\n",
    "\n",
    "compteur_filtre = {mot: nb for mot, nb in compteur.items() if nb >= 500}\n",
    "\n",
    "compteur_filtre_trie = dict(sorted(compteur_filtre.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "print('On a réduit le nombre total de \"mots-clés\" de :',len(liste), \"à \",len(compteur_filtre_trie))\n",
    "print(compteur_filtre_trie)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4098ef3b-6ecb-4269-b90c-694431176c7b",
   "metadata": {},
   "source": [
    "## En pure comparaison, j'ai demandé à chatGPT de me choisir les mots importants dans la liste L avec les 570000 mots : voici le résultat : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "10412772-1fb9-4156-824e-1fc7a061d7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_filtré = {\n",
    "    'electric': 5740,\n",
    "    'vehicle': 5629,\n",
    "    'energy': 3708,\n",
    "    'system': 3624,\n",
    "    'study': 3278,\n",
    "    'model': 3164,\n",
    "    'battery': 2693,\n",
    "    'charging': 2587,\n",
    "    'power': 2513,\n",
    "    'transport': 2298,\n",
    "    'electrification': 2077,\n",
    "    'emission': 2042,\n",
    "    'cost': 2026,\n",
    "    'analysis': 1940,\n",
    "    'impact': 1845,\n",
    "    'demand': 1806,\n",
    "    'technology': 1711,\n",
    "    'method': 1708,\n",
    "    'strategy': 1635,\n",
    "    'performance': 1578,\n",
    "    'approach': 1546,\n",
    "    'data': 1524,\n",
    "    'fuel': 1471,\n",
    "    'simulation': 1411,\n",
    "    'electricity': 1405,\n",
    "    'carbon': 1376,\n",
    "    'reduce': 1364,\n",
    "    'network': 1310,\n",
    "    'sector': 1301,\n",
    "    'transportation': 1294,\n",
    "    'research': 1285,\n",
    "    'solution': 1282,\n",
    "    'operation': 1244,\n",
    "    'consumption': 1242,\n",
    "    'optimization': 1241,\n",
    "    'grid': 1230,\n",
    "    'efficiency': 1225,\n",
    "    'infrastructure': 1205,\n",
    "    'development': 1172,\n",
    "    'environmental': 1171,\n",
    "    'management': 1152,\n",
    "    'reduction': 1133,\n",
    "    'optimal': 1131,\n",
    "    'range': 1126,\n",
    "    'hybrid': 1119,\n",
    "    'renewable': 1110,\n",
    "    'policy': 1100,\n",
    "    'driving': 1091,\n",
    "    'source': 1069,\n",
    "    'algorithm': 1069,\n",
    "    'station': 1043,\n",
    "    'capacity': 1020,\n",
    "    'design': 978,\n",
    "    'storage': 978,\n",
    "    'distribution': 973,\n",
    "    'process': 940,\n",
    "    'dynamic': 934,\n",
    "    'application': 917,\n",
    "    'generation': 874,\n",
    "    'charge': 871,\n",
    "    'economic': 863,\n",
    "    'adoption': 846,\n",
    "    'framework': 844,\n",
    "    'conventional': 827,\n",
    "    'fleet': 819,\n",
    "    'public': 818,\n",
    "    'urban': 812,\n",
    "    'dioxide': 809,\n",
    "    'greenhouse': 801,\n",
    "    'sustainable': 792,\n",
    "    'parameter': 781,\n",
    "    'transition': 760,\n",
    "    'behavior': 760,\n",
    "    'key': 759,\n",
    "    'mobility': 725,\n",
    "    'cycle': 721,\n",
    "    'supply': 712,\n",
    "    'characteristic': 704,\n",
    "    'service': 699,\n",
    "    'reducing': 679,\n",
    "    'engine': 677,\n",
    "    'operating': 664,\n",
    "    'climate': 654,\n",
    "    'cell': 635,\n",
    "    'alternative': 633,\n",
    "    'planning': 630,\n",
    "    'internal': 628,\n",
    "    'modeling': 626,\n",
    "    'efficient': 621,\n",
    "    'mode': 619,\n",
    "    'industry': 618,\n",
    "    'air': 615,\n",
    "    'objective': 609,\n",
    "    'combustion': 608,\n",
    "    'environment': 605,\n",
    "    'production': 602,\n",
    "    'effective': 591,\n",
    "    'integration': 559,\n",
    "    'electrical': 545,\n",
    "    'bus': 538,\n",
    "    'smart': 502,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "19e97b1d-6286-4065-9d28-fafadbdedbfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n"
     ]
    }
   ],
   "source": [
    "print(len(dico_filtré)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5263a885-bd99-43e6-a011-92c4b98394c3",
   "metadata": {},
   "source": [
    "On passe de 234 mots avec ma méthode à 101 mots avec chatGPT. Sur 570 000 mots d'origine, je considère que ma méthode est plutôt satisfaisante, surtout que les 101 mots sont bien compris "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6c95aaa3-efca-44c2-be4c-027dfd589d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'electric': 100.0, 'vehicle': 98.09, 'energy': 65.09, 'system': 63.64, 'study': 57.7, 'model': 55.74, 'battery': 47.65, 'charging': 45.82, 'power': 44.55, 'transport': 40.86, 'electrification': 37.06, 'emission': 36.46, 'cost': 36.19, 'analysis': 34.71, 'impact': 33.08, 'demand': 32.41, 'technology': 30.77, 'method': 30.72, 'strategy': 29.47, 'performance': 28.49, 'approach': 27.94, 'data': 27.56, 'fuel': 26.65, 'simulation': 25.62, 'electricity': 25.52, 'carbon': 25.02, 'reduce': 24.81, 'network': 23.88, 'sector': 23.73, 'transportation': 23.61, 'research': 23.45, 'solution': 23.4, 'operation': 22.75, 'consumption': 22.71, 'optimization': 22.7, 'grid': 22.51, 'efficiency': 22.42, 'infrastructure': 22.08, 'development': 21.51, 'environmental': 21.49, 'management': 21.17, 'reduction': 20.84, 'optimal': 20.81, 'range': 20.72, 'hybrid': 20.6, 'renewable': 20.45, 'policy': 20.27, 'driving': 20.12, 'source': 19.74, 'algorithm': 19.74, 'station': 19.3, 'capacity': 18.9, 'design': 18.18, 'storage': 18.18, 'distribution': 18.09, 'process': 17.53, 'dynamic': 17.42, 'application': 17.13, 'generation': 16.39, 'charge': 16.34, 'economic': 16.2, 'adoption': 15.91, 'framework': 15.88, 'conventional': 15.58, 'fleet': 15.45, 'public': 15.43, 'urban': 15.33, 'dioxide': 15.27, 'greenhouse': 15.14, 'sustainable': 14.98, 'parameter': 14.79, 'transition': 14.43, 'behavior': 14.43, 'key': 14.42, 'mobility': 13.83, 'cycle': 13.76, 'supply': 13.61, 'characteristic': 13.47, 'service': 13.38, 'reducing': 13.04, 'engine': 13.01, 'operating': 12.78, 'climate': 12.61, 'cell': 12.29, 'alternative': 12.25, 'planning': 12.2, 'internal': 12.16, 'modeling': 12.13, 'efficient': 12.04, 'mode': 12.01, 'industry': 11.99, 'air': 11.94, 'objective': 11.84, 'combustion': 11.82, 'environment': 11.77, 'production': 11.72, 'effective': 11.53, 'integration': 10.98, 'electrical': 10.74, 'bus': 10.62, 'smart': 10.0}\n"
     ]
    }
   ],
   "source": [
    "# On veut maintenant calculer des poids d'importance des mots pour qu'on puisse attribuer à chaque mot un rayon plus ou moins grand. \n",
    "# On fait une echelle pour avoir des rayons compris entre 10 et 100. \n",
    "def scale(freq, min_freq, max_freq, min_scale=10, max_scale=100):\n",
    "    return min_scale + (freq - min_freq) * (max_scale - min_scale) / (max_freq - min_freq)\n",
    "\n",
    "min_freq = min(dico_filtré.values())\n",
    "max_freq = max(dico_filtré.values())\n",
    "\n",
    "rayon_mots = {\n",
    "    mot: round(scale(freq, min_freq, max_freq), 2)\n",
    "    for mot, freq in dico_filtré.items()\n",
    "}\n",
    "\n",
    "print(rayon_mots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5d52f302-b126-438d-af66-7c8f8d8dc09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101, 101)\n",
      "          electric  vehicle  energy  system  study  model  battery  charging  \\\n",
      "electric         0     5249    2970    2937   2722   2668     2454      2469   \n",
      "vehicle       5249        0    2916    2854   2654   2613     2359      2355   \n",
      "energy        2970     2916       0    2221   1699   1673     1551      1346   \n",
      "system        2937     2854    2221       0   1660   1662     1449      1384   \n",
      "study         2722     2654    1699    1660      0   1552     1266      1254   \n",
      "\n",
      "          power  transport  ...  air  objective  combustion  environment  \\\n",
      "electric   2124       1555  ...  486        534         542          493   \n",
      "vehicle    2022       1465  ...  490        521         555          485   \n",
      "energy     1669       1312  ...  333        378         321          352   \n",
      "system     1679       1191  ...  324        356         226          326   \n",
      "study      1078       1059  ...  281        302         302          280   \n",
      "\n",
      "          production  effective  integration  electrical  bus  smart  \n",
      "electric         435        510          472         412  474    456  \n",
      "vehicle          429        495          462         386  372    440  \n",
      "energy           406        310          405         350  302    360  \n",
      "system           295        312          413         352  307    329  \n",
      "study            293        297          263         219  263    238  \n",
      "\n",
      "[5 rows x 101 columns]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import itertools\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "tous_mots = list(dico_filtré)\n",
    "\n",
    "cooc_matrice = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "# On parcourt chaque sous-liste de mots (chaque titre)\n",
    "for mots in L:\n",
    "    mots_filtres = [m for m in set(mots) if m in tous_mots] \n",
    "    for w1, w2 in itertools.combinations(mots_filtres, 2):\n",
    "        cooc_matrice[w1][w2] += 1\n",
    "        cooc_matrice[w2][w1] += 1  #comme on aura une matrice symétrique, on essaie de réduire la complexité en ne parcourant pas deux fois\n",
    "        \n",
    "df_cooc = pd.DataFrame(cooc_matrice, index=tous_mots, columns=tous_mots).fillna(0).astype(int)\n",
    "\n",
    "\n",
    "print(df_cooc.shape)  \n",
    "print(df_cooc.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f93d225f-6f45-466e-aa6d-2aa0e154967b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117 liens trouvés avec cooccurrence > 1000\n",
      "[('electric', 'vehicle'), ('electric', 'energy'), ('electric', 'system'), ('electric', 'study'), ('electric', 'model'), ('electric', 'battery'), ('electric', 'charging'), ('electric', 'power'), ('electric', 'transport'), ('electric', 'electrification'), ('electric', 'emission'), ('electric', 'cost'), ('electric', 'analysis'), ('electric', 'impact'), ('electric', 'demand'), ('electric', 'technology'), ('electric', 'method'), ('electric', 'strategy'), ('electric', 'performance'), ('electric', 'approach'), ('electric', 'data'), ('electric', 'fuel'), ('electric', 'simulation'), ('electric', 'electricity'), ('electric', 'carbon'), ('electric', 'reduce'), ('electric', 'network'), ('electric', 'transportation'), ('electric', 'research'), ('electric', 'solution'), ('electric', 'operation'), ('electric', 'consumption'), ('electric', 'optimization'), ('electric', 'grid'), ('electric', 'infrastructure'), ('electric', 'management'), ('electric', 'optimal'), ('electric', 'hybrid'), ('vehicle', 'energy'), ('vehicle', 'system'), ('vehicle', 'study'), ('vehicle', 'model'), ('vehicle', 'battery'), ('vehicle', 'charging'), ('vehicle', 'power'), ('vehicle', 'transport'), ('vehicle', 'electrification'), ('vehicle', 'emission'), ('vehicle', 'cost'), ('vehicle', 'analysis'), ('vehicle', 'impact'), ('vehicle', 'demand'), ('vehicle', 'technology'), ('vehicle', 'method'), ('vehicle', 'strategy'), ('vehicle', 'performance'), ('vehicle', 'approach'), ('vehicle', 'data'), ('vehicle', 'fuel'), ('vehicle', 'simulation'), ('vehicle', 'electricity'), ('vehicle', 'carbon'), ('vehicle', 'reduce'), ('vehicle', 'network'), ('vehicle', 'transportation'), ('vehicle', 'research'), ('vehicle', 'solution'), ('vehicle', 'consumption'), ('vehicle', 'optimization'), ('vehicle', 'grid'), ('vehicle', 'infrastructure'), ('vehicle', 'management'), ('vehicle', 'hybrid'), ('vehicle', 'driving'), ('energy', 'system'), ('energy', 'study'), ('energy', 'model'), ('energy', 'battery'), ('energy', 'charging'), ('energy', 'power'), ('energy', 'transport'), ('energy', 'electrification'), ('energy', 'emission'), ('energy', 'cost'), ('energy', 'analysis'), ('energy', 'impact'), ('energy', 'demand'), ('energy', 'technology'), ('energy', 'electricity'), ('energy', 'consumption'), ('energy', 'renewable'), ('system', 'study'), ('system', 'model'), ('system', 'battery'), ('system', 'charging'), ('system', 'power'), ('system', 'transport'), ('system', 'electrification'), ('system', 'cost'), ('system', 'demand'), ('study', 'model'), ('study', 'battery'), ('study', 'charging'), ('study', 'power'), ('study', 'transport'), ('study', 'emission'), ('study', 'analysis'), ('study', 'impact'), ('model', 'battery'), ('model', 'charging'), ('model', 'power'), ('model', 'cost'), ('battery', 'charging'), ('battery', 'power'), ('charging', 'power'), ('transport', 'electrification'), ('emission', 'carbon')]\n"
     ]
    }
   ],
   "source": [
    "### Liens entre les bulles de mots \n",
    "\n",
    "liens= []\n",
    "\n",
    "for a, b in itertools.combinations(df_cooc.columns, 2):\n",
    "    if df_cooc.loc[a, b] > 1000:  # on choisi de garder que les mots que reviennent ensemble de les titres plus de 1000 fois.\n",
    "        liens.append((a, b))\n",
    "\n",
    "print(f\"{len(liens)} liens trouvés avec cooccurrence > 1000\")\n",
    "print(liens)  # aperçu des premières paires\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106d3015-4073-4485-afe4-3004f2f612b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
