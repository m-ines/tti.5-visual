{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dc2c3fe-9299-42dc-aa08-12714b2f1212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                Étiquette  Nombre_de_récurrence\n",
      "0                                       0                 67495\n",
      "1                       electric vehicles                  2675\n",
      "2                         electrification                  1253\n",
      "3                        electric vehicle                   558\n",
      "4               battery electric vehicles                   437\n",
      "...                                   ...                   ...\n",
      "23195                  system variability                     1\n",
      "23196         generation plant investment                     1\n",
      "23197                  total system costs                     1\n",
      "23198  variable renewable energy sources.                     1\n",
      "23199                        resource use                     1\n",
      "\n",
      "[23200 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#2. Relier les bulles connectées entre elles \n",
    "\n",
    "import dash\n",
    "from dash import html, dcc, Input, Output\n",
    "import plotly.graph_objects as go\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "### Etude du fichier csv et compte des étiquettes \n",
    "\n",
    "df = pd.read_csv(\"Data_20250506.csv\", sep=';')\n",
    "\n",
    "etiquettes_data = df.iloc[:, 11:]  # à partir de la colonne 12, on prend tous les mots clés des études scientifiques \n",
    "etiquettes_series = pd.Series(etiquettes_data.values.ravel())\n",
    "\n",
    "# Nettoyage des valeurs : on enlève les cases vides, les majuscules...car sinon on compterait différemment Fer et fer par exemple\n",
    "\n",
    "etiquettes_series = etiquettes_series.dropna().astype(str).str.strip().str.lower() \n",
    "\n",
    "etiquettes_comptes = etiquettes_series.value_counts().reset_index()  # compte le nombre d'occurences dans toute la littérature scientifique\n",
    "etiquettes_comptes.columns = ['Étiquette', 'Nombre_de_récurrence']\n",
    "\n",
    "print(etiquettes_comptes)\n",
    "\n",
    "\n",
    "\n",
    "#### A ce point la, certains mots sont encore compté deux fois différement  = electric vehicles et elecric vehicle par exmple !\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9acfb48c-95af-4a3a-9277-5c81338445ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ewenm\\miniconda3\\Lib\\site-packages\\nltk\\metrics\\association.py:26: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 2.3.1)\n",
      "  from scipy.stats import fisher_exact\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ewenm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\ewenm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenise \n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78a48ac7-9588-4dfc-b1c8-d609f64bcdbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Electric vehicles have been developed with the aims of saving energy and reducing carbon dioxide emissions. Furthermore, as a single bus can transport many people, buses produce low carbon dioxide emissions per person in comparison with cars. In recent years, community buses have been introduced to ensure the mobility of senior citizens. Therefore, a low-floor vehicle was adopted as the base vehicle in our latest project. The bus was demonstrated around the center of the city. It followed a circular route of distance 7.2 kilometers, the number of bus stops on the route was 27 and the driving time was 40 minutes per circuit. This demonstration was repeated three to four times a day for 14 days. During the 86 circuits of the demonstration, a total of 1,110 passengers used the bus and the total running distance was 776 kilometers. From these results, we concluded that the quantity of carbon dioxide emissions could be reduced by 37% using our proposed bus in comparison with that of a conventional diesel-engine bus.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "text=df['AB_AI'][0]\n",
    "print(text)\n",
    "\n",
    "tokens = word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bb61601-2438-4595-974e-9912bd5d481e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nombre de mots de text : 1026\n",
      "nombre de mots de words : 187\n",
      "nombre de mots de W ( sans ponctuation) : 88\n",
      "nombre de mots de W_sans_ED : 78\n",
      "['people', 'saving', 'emissions', 'could', 'During', 'low-floor', 'The', '776', 'time', 'mobility', 'city', 'aims', 'produce', 'running', 'years', 'results', 'number', 'four', 'base', 'per', '14', 'conventional', 'quantity', 'stops', 'distance', 'reducing', 'times', 'transport', 'In', 'Furthermore', 'From', 'three', 'driving', 'days', 'day', '27', 'Therefore', 'bus', 'center', 'single', 'using', 'Electric', 'cars', '37', 'circuit', 'circular', 'recent', 'total', 'person', 'It', 'carbon', 'vehicle', 'kilometers', 'demonstration', 'route', 'low', 'comparison', 'citizens', 'This', 'ensure', 'senior', 'vehicles', '7.2', '86', 'diesel-engine', 'around', 'many', 'passengers', 'dioxide', 'buses', 'circuits', 'community', '1,110', 'energy', 'latest', 'minutes', 'project', '40']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ewenm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Virons les stop words \n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stopwords = set(stopwords.words('english'))\n",
    "print('nombre de mots de text :' , len(text))\n",
    "words = word_tokenize(text)\n",
    "words_filtered = []\n",
    "print('nombre de mots de words :' , len(words))\n",
    "# on va renvoyer une liste des mots en ne gardant \"que les plus importants\". On enlève par exemple les \"is\", \"of... En somme, on ne garde que les mots clés.\n",
    "for w in words:\n",
    "  if w not in stopwords:\n",
    "    words_filtered.append(w)\n",
    "\n",
    "\n",
    "\n",
    "# J'enlève maintenant toute la ponctuation de ma liste de mots. \n",
    "ponctuation = ['.',',',';','?',':','!','%']\n",
    "words_sans_ponctuation=[x for x in words_filtered if x not in ponctuation]\n",
    "\n",
    "\n",
    "# on a beaucoup de doublons dans la liste : on les retire pour diminuer le nombre de mots \n",
    "W=list(set(words_sans_ponctuation))\n",
    "print('nombre de mots de W ( sans ponctuation) :' , len(W))\n",
    "\n",
    "\n",
    "# on fait un choix : on enlève les mots qui terminent par \"ED\" en anglais car on estime que ce sont des verbes, et non les principaux mots-clés. \n",
    "# parce que les encadrants préfèrent. On pourrait enlever cette ligne. \n",
    "\n",
    "W_sans_ED = [w for w in W if not w.lower().endswith(\"ed\")] \n",
    "print('nombre de mots de W_sans_ED :' , len(W_sans_ED))\n",
    "print(W_sans_ED)\n",
    "\n",
    "# A ce stade on a réussi à réduire le nombre de mots clés de 1026 mots à 79. Ca rste encore beaucoup trop si on veut traiter beaucoup d'articles en meme temps. \n",
    "sans_maj = [w.lower() for w in W_sans_ED]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74bca924-39b4-4fb3-bddb-faafcd98466e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nombre de mots de mots_filtrés : 72\n",
      "['people', 'saving', 'emissions', 'could', 'low-floor', '776', 'time', 'mobility', 'city', 'aims', 'produce', 'running', 'years', 'results', 'number', 'four', 'base', 'per', '14', 'conventional', 'quantity', 'stops', 'distance', 'reducing', 'times', 'transport', 'furthermore', 'three', 'driving', 'days', 'day', '27', 'therefore', 'bus', 'center', 'single', 'using', 'electric', 'cars', '37', 'circuit', 'circular', 'recent', 'total', 'person', 'carbon', 'vehicle', 'kilometers', 'demonstration', 'route', 'low', 'comparison', 'citizens', 'ensure', 'senior', 'vehicles', '7.2', '86', 'diesel-engine', 'around', 'many', 'passengers', 'dioxide', 'buses', 'circuits', 'community', '1,110', 'energy', 'latest', 'minutes', 'project', '40']\n"
     ]
    }
   ],
   "source": [
    "# on enlève les majuscules pour pouvoir enlever les stopwords qui contenaient des majuscules \n",
    "mots_filtrés =[]\n",
    "for w in sans_maj:\n",
    "  if w not in stopwords:\n",
    "    mots_filtrés.append(w)\n",
    "\n",
    "print('nombre de mots de mots_filtrés :' , len(mots_filtrés))\n",
    "print(mots_filtrés)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b68aa35b-c6f4-4045-a204-48c4a5db61a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ewenm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\ewenm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nombre de mots de W_singuliers 67\n",
      "['four', 'base', 'per', '14', 'conventional', 'people', 'quantity', 'result', 'therefore', 'ensure', 'senior', 'saving', 'passenger', 'distance', '37', 'could', '7.2', '86', 'diesel-engine', 'aim', 'circuit', 'around', 'reducing', 'low-floor', 'minute', 'circular', 'year', 'many', 'recent', 'furthermore', 'total', 'dioxide', 'person', '776', 'car', 'transport', 'electric', 'time', 'carbon', 'emission', 'mobility', 'vehicle', 'city', 'three', 'produce', 'kilometer', 'community', 'driving', 'stop', 'running', 'demonstration', '1,110', 'energy', 'day', 'latest', '27', 'route', 'citizen', 'low', 'project', 'bus', 'center', 'comparison', 'number', 'single', 'using', '40']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Mise au singulier\n",
    "W_singuliers = list(set([lemmatizer.lemmatize(w, pos='n') for w in mots_filtrés]))\n",
    "\n",
    "print('nombre de mots de W_singuliers', len(W_singuliers))\n",
    "print(W_singuliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f932361-a023-4f5f-a293-ebffa255639b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nombre de mots de mots_assez_long 62\n",
      "['four', 'base', 'per', 'conventional', 'people', 'quantity', 'result', 'therefore', 'ensure', 'senior', 'saving', 'passenger', 'distance', 'could', '7.2', 'diesel-engine', 'aim', 'circuit', 'around', 'reducing', 'low-floor', 'minute', 'circular', 'year', 'many', 'recent', 'furthermore', 'total', 'dioxide', 'person', '776', 'car', 'transport', 'electric', 'time', 'carbon', 'emission', 'mobility', 'vehicle', 'city', 'three', 'produce', 'kilometer', 'community', 'driving', 'stop', 'running', 'demonstration', '1,110', 'energy', 'day', 'latest', 'route', 'citizen', 'low', 'project', 'bus', 'center', 'comparison', 'number', 'single', 'using']\n"
     ]
    }
   ],
   "source": [
    "# j'enlève les mots de moins de 3 caractères ; \n",
    "mots_assez_long = []\n",
    "for w in W_singuliers : \n",
    "    if len(w)>=3 : \n",
    "        mots_assez_long.append(w)\n",
    "\n",
    "print('nombre de mots de mots_assez_long', len(mots_assez_long))\n",
    "print(mots_assez_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f304b5e3-3d1a-4f2a-a5bd-c600c9655ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nombre de mots de W_sans_nombres 59\n",
      "['four', 'base', 'per', 'conventional', 'people', 'quantity', 'result', 'therefore', 'ensure', 'senior', 'saving', 'passenger', 'distance', 'could', 'diesel-engine', 'aim', 'circuit', 'around', 'reducing', 'low-floor', 'minute', 'circular', 'year', 'many', 'recent', 'furthermore', 'total', 'dioxide', 'person', 'car', 'transport', 'electric', 'time', 'carbon', 'emission', 'mobility', 'vehicle', 'city', 'three', 'produce', 'kilometer', 'community', 'driving', 'stop', 'running', 'demonstration', 'energy', 'day', 'latest', 'route', 'citizen', 'low', 'project', 'bus', 'center', 'comparison', 'number', 'single', 'using']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def est_nombre(w):\n",
    "    return re.fullmatch(r\"[0-9]+([.,][0-9]+)?\", w) is not None\n",
    "\n",
    "W_sans_nombres = [w for w in mots_assez_long if not est_nombre(w)]\n",
    "\n",
    "print('nombre de mots de W_sans_nombres', len(W_sans_nombres))\n",
    "print(W_sans_nombres)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2aa8e0-007a-4827-8408-d51dfaaf2f5a",
   "metadata": {},
   "source": [
    "On a réussi à passer de 1026 mots à 59 ! Il me faudrait maintenant une IA pour enlever les mots ayant moins d'intéret en fonction du sujet pour sélectionner les mots clé importants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8174ba8d-a792-43a9-a1dc-4069d4445431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7100\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(len(df['AB_AI']))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd6c4527-3b5e-4c32-8e3d-ebdb269c9629",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ewenm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ewenm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\ewenm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Faisons une fonction plus rapide pour sélectionner les mots importants d'un titre d'article : \n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "import re\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stopwords = set(stopwords.words('english'))\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "def est_nombre(w):\n",
    "        return re.fullmatch(r\"[0-9]+([.,][0-9]+)?\", w) is not None\n",
    "\n",
    "\n",
    "def mots_cles(text) : \n",
    "\n",
    "\n",
    "    words = word_tokenize(text)\n",
    "    sans_maj = [w.lower() for w in words]\n",
    "    words_filtered = []\n",
    "    for w in sans_maj:\n",
    "      if w not in stopwords:\n",
    "        words_filtered.append(w)\n",
    "\n",
    "\n",
    "#ponctuation \n",
    "    ponctuation = ['.',',',';','?',':','!','%']\n",
    "    words_sans_ponctuation=[x for x in words_filtered if x not in ponctuation]\n",
    "\n",
    "\n",
    "# doublons\n",
    "    W=list(set(words_sans_ponctuation))\n",
    "\n",
    "# sans les -ED\n",
    "    W_sans_ED = [w for w in W if not w.lower().endswith(\"ed\")] \n",
    "\n",
    "# singulier\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    W_singuliers = list(set([lemmatizer.lemmatize(w, pos='n') for w in W_sans_ED]))\n",
    "\n",
    "#sans les mots très courts\n",
    "    mots_assez_long = []\n",
    "    for w in W_singuliers : \n",
    "        if len(w)>=3 : \n",
    "            mots_assez_long.append(w)\n",
    "\n",
    "# sans les nombres \n",
    "   \n",
    "    W_sans_nombres = [w for w in mots_assez_long if not est_nombre(w)]\n",
    "\n",
    "    return(W_sans_nombres)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12a8e23c-9b88-4d38-b51f-a9332de71b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nombre de mots dans liste : 570379\n",
      "nombre de mots dans phrase :  18409\n"
     ]
    }
   ],
   "source": [
    "L = []\n",
    "\n",
    "#On vai maintenant parcourir tous les titres !\n",
    "for i in range (len(df['AB_AI'])) : \n",
    "    L.append(mots_cles(df['AB_AI'][i]))\n",
    "\n",
    "\n",
    "liste = [mot for sous_liste in L for mot in sous_liste]\n",
    "print('nombre de mots dans liste :',len(liste))  \n",
    "phrase = ' '.join(liste)\n",
    "\n",
    "print('nombre de mots dans phrase : ',len(mots_cles(phrase))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0734632b-7390-4583-96a8-03d120c3987f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "# Je range dans un dictionnaire le mot et son nombre d'apparition dans l'ensemble des titres, et ce par ordre décroissant d'apparition.\n",
    "compteur = Counter(liste)\n",
    "dico_trie = dict(compteur.most_common())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c77cca1-af8c-40c2-adce-9b89d5e09310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On a réduit le nombre total de \"mots-clés\" de : 570379 à  234\n",
      "{'electric': 5740, 'vehicle': 5629, 'result': 3733, 'energy': 3708, 'system': 3623, 'study': 3277, 'model': 3163, 'paper': 3098, 'battery': 2693, 'charging': 2587, 'power': 2513, 'transport': 2298, 'using': 2278, 'electrification': 2077, 'different': 2068, 'emission': 2042, 'cost': 2026, 'also': 1998, 'show': 1981, 'analysis': 1940, 'however': 1855, 'impact': 1845, 'demand': 1806, 'technology': 1711, 'method': 1706, 'strategy': 1635, 'time': 1633, 'potential': 1578, 'performance': 1578, 'approach': 1546, 'data': 1524, 'use': 1479, 'fuel': 1471, 'increase': 1459, 'simulation': 1411, 'due': 1408, 'electricity': 1405, 'present': 1402, 'current': 1389, 'significant': 1387, 'high': 1379, 'carbon': 1376, 'reduce': 1364, 'network': 1308, 'sector': 1301, 'new': 1298, 'transportation': 1293, 'case': 1292, 'two': 1289, 'research': 1284, 'solution': 1282, 'scenario': 1260, 'operation': 1244, 'consumption': 1242, 'one': 1242, 'optimization': 1241, 'grid': 1230, 'efficiency': 1225, 'future': 1214, 'infrastructure': 1205, 'problem': 1182, 'development': 1172, 'environmental': 1171, 'challenge': 1156, 'management': 1152, 'effect': 1143, 'reduction': 1133, 'optimal': 1131, 'range': 1126, 'hybrid': 1119, 'renewable': 1110, 'level': 1109, 'policy': 1100, 'driving': 1091, 'condition': 1087, 'including': 1084, 'source': 1069, 'algorithm': 1069, 'load': 1063, 'control': 1061, 'change': 1047, 'station': 1043, 'gas': 1029, 'considering': 1025, 'capacity': 1020, 'factor': 1017, 'various': 1009, 'market': 999, 'provide': 986, 'design': 978, 'storage': 978, 'distribution': 973, 'well': 959, 'process': 940, 'dynamic': 934, 'application': 917, 'total': 913, 'number': 893, 'benefit': 888, 'could': 884, 'work': 881, 'generation': 874, 'charge': 871, 'area': 869, 'economic': 863, 'increasing': 862, 'important': 858, 'adoption': 846, 'framework': 844, 'aim': 842, 'conventional': 827, 'significantly': 825, 'three': 822, 'fleet': 819, 'year': 818, 'public': 818, 'first': 815, 'urban': 812, 'dioxide': 809, 'greenhouse': 801, 'issue': 800, 'per': 793, 'sustainable': 792, 'higher': 789, 'low': 788, 'parameter': 781, 'rate': 779, 'achieve': 777, 'global': 775, 'may': 774, 'finally': 763, 'behavior': 760, 'key': 759, 'transition': 759, 'region': 756, 'therefore': 746, 'finding': 744, 'within': 743, 'term': 741, 'state': 739, 'existing': 734, 'type': 731, 'mobility': 725, 'furthermore': 723, 'road': 722, 'cycle': 721, 'improve': 713, 'supply': 712, 'role': 712, 'characteristic': 704, 'novel': 700, 'service': 699, 'address': 697, 'main': 690, 'lower': 689, 'addition': 684, 'reducing': 679, 'value': 679, 'engine': 677, 'large': 674, 'price': 674, 'operating': 664, 'focus': 664, 'provides': 662, 'order': 659, 'proposes': 659, 'support': 657, 'test': 656, 'climate': 654, 'temperature': 647, 'several': 636, 'cell': 635, 'alternative': 633, 'planning': 630, 'internal': 628, 'modeling': 626, 'efficient': 621, 'mode': 619, 'industry': 617, 'air': 615, 'objective': 609, 'combustion': 608, 'environment': 605, 'production': 602, 'demonstrate': 598, 'effective': 591, 'moreover': 591, 'indicate': 590, 'without': 582, 'specific': 581, 'overall': 578, 'thus': 577, 'voltage': 576, 'resource': 575, 'influence': 570, 'among': 565, 'respectively': 564, 'integration': 558, 'peak': 558, 'set': 556, 'many': 553, 'user': 553, 'uncertainty': 551, 'direct': 549, 'less': 548, 'local': 545, 'electrical': 545, 'lead': 543, 'major': 539, 'bus': 538, 'available': 538, 'towards': 537, 'requirement': 534, 'effectiveness': 533, 'component': 532, 'plug-in': 529, 'better': 523, 'found': 517, 'target': 516, 'average': 516, 'point': 515, 'thermal': 511, 'operational': 510, 'heat': 509, 'location': 508, 'decision': 507, 'literature': 506, 'context': 506, 'passenger': 504, 'life': 504, 'goal': 503, 'smart': 502, 'flow': 501, 'comprehensive': 500}\n"
     ]
    }
   ],
   "source": [
    "# Je supprime tous les mots qui apparaissent moins de 500 fois en supposant ainsi que ce sont des mots peu importants, que je n'avais pas pu supprimer avant.\n",
    "\n",
    "compteur_filtre = {mot: nb for mot, nb in compteur.items() if nb >= 500}\n",
    "\n",
    "compteur_filtre_trie = dict(sorted(compteur_filtre.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "print('On a réduit le nombre total de \"mots-clés\" de :',len(liste), \"à \",len(compteur_filtre_trie))\n",
    "print(compteur_filtre_trie)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4098ef3b-6ecb-4269-b90c-694431176c7b",
   "metadata": {},
   "source": [
    "## En pure comparaison, j'ai demandé à chatGPT de me choisir les mots importants dans la liste L avec les 570000 mots : voici le résultat : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10412772-1fb9-4156-824e-1fc7a061d7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_filtré = {\n",
    "    'electric': 5740,\n",
    "    'vehicle': 5629,\n",
    "    'energy': 3708,\n",
    "    'system': 3624,\n",
    "    'study': 3278,\n",
    "    'model': 3164,\n",
    "    'battery': 2693,\n",
    "    'charging': 2587,\n",
    "    'power': 2513,\n",
    "    'transport': 2298,\n",
    "    'electrification': 2077,\n",
    "    'emission': 2042,\n",
    "    'cost': 2026,\n",
    "    'analysis': 1940,\n",
    "    'impact': 1845,\n",
    "    'demand': 1806,\n",
    "    'technology': 1711,\n",
    "    'method': 1708,\n",
    "    'strategy': 1635,\n",
    "    'performance': 1578,\n",
    "    'approach': 1546,\n",
    "    'data': 1524,\n",
    "    'fuel': 1471,\n",
    "    'simulation': 1411,\n",
    "    'electricity': 1405,\n",
    "    'carbon': 1376,\n",
    "    'reduce': 1364,\n",
    "    'network': 1310,\n",
    "    'sector': 1301,\n",
    "    'transportation': 1294,\n",
    "    'research': 1285,\n",
    "    'solution': 1282,\n",
    "    'operation': 1244,\n",
    "    'consumption': 1242,\n",
    "    'optimization': 1241,\n",
    "    'grid': 1230,\n",
    "    'efficiency': 1225,\n",
    "    'infrastructure': 1205,\n",
    "    'development': 1172,\n",
    "    'environmental': 1171,\n",
    "    'management': 1152,\n",
    "    'reduction': 1133,\n",
    "    'optimal': 1131,\n",
    "    'range': 1126,\n",
    "    'hybrid': 1119,\n",
    "    'renewable': 1110,\n",
    "    'policy': 1100,\n",
    "    'driving': 1091,\n",
    "    'source': 1069,\n",
    "    'algorithm': 1069,\n",
    "    'station': 1043,\n",
    "    'capacity': 1020,\n",
    "    'design': 978,\n",
    "    'storage': 978,\n",
    "    'distribution': 973,\n",
    "    'process': 940,\n",
    "    'dynamic': 934,\n",
    "    'application': 917,\n",
    "    'generation': 874,\n",
    "    'charge': 871,\n",
    "    'economic': 863,\n",
    "    'adoption': 846,\n",
    "    'framework': 844,\n",
    "    'conventional': 827,\n",
    "    'fleet': 819,\n",
    "    'public': 818,\n",
    "    'urban': 812,\n",
    "    'dioxide': 809,\n",
    "    'greenhouse': 801,\n",
    "    'sustainable': 792,\n",
    "    'parameter': 781,\n",
    "    'transition': 760,\n",
    "    'behavior': 760,\n",
    "    'key': 759,\n",
    "    'mobility': 725,\n",
    "    'cycle': 721,\n",
    "    'supply': 712,\n",
    "    'characteristic': 704,\n",
    "    'service': 699,\n",
    "    'reducing': 679,\n",
    "    'engine': 677,\n",
    "    'operating': 664,\n",
    "    'climate': 654,\n",
    "    'cell': 635,\n",
    "    'alternative': 633,\n",
    "    'planning': 630,\n",
    "    'internal': 628,\n",
    "    'modeling': 626,\n",
    "    'efficient': 621,\n",
    "    'mode': 619,\n",
    "    'industry': 618,\n",
    "    'air': 615,\n",
    "    'objective': 609,\n",
    "    'combustion': 608,\n",
    "    'environment': 605,\n",
    "    'production': 602,\n",
    "    'effective': 591,\n",
    "    'integration': 559,\n",
    "    'electrical': 545,\n",
    "    'bus': 538,\n",
    "    'smart': 502,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19e97b1d-6286-4065-9d28-fafadbdedbfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n"
     ]
    }
   ],
   "source": [
    "print(len(dico_filtré)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5263a885-bd99-43e6-a011-92c4b98394c3",
   "metadata": {},
   "source": [
    "On passe de 234 mots avec ma méthode à 101 mots avec chatGPT. Sur 570 000 mots d'origine, je considère que ma méthode est plutôt satisfaisante, surtout que les 101 mots sont bien compris "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c95aaa3-efca-44c2-be4c-027dfd589d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'electric': 100.0, 'vehicle': 98.09, 'energy': 65.09, 'system': 63.64, 'study': 57.7, 'model': 55.74, 'battery': 47.65, 'charging': 45.82, 'power': 44.55, 'transport': 40.86, 'electrification': 37.06, 'emission': 36.46, 'cost': 36.19, 'analysis': 34.71, 'impact': 33.08, 'demand': 32.41, 'technology': 30.77, 'method': 30.72, 'strategy': 29.47, 'performance': 28.49, 'approach': 27.94, 'data': 27.56, 'fuel': 26.65, 'simulation': 25.62, 'electricity': 25.52, 'carbon': 25.02, 'reduce': 24.81, 'network': 23.88, 'sector': 23.73, 'transportation': 23.61, 'research': 23.45, 'solution': 23.4, 'operation': 22.75, 'consumption': 22.71, 'optimization': 22.7, 'grid': 22.51, 'efficiency': 22.42, 'infrastructure': 22.08, 'development': 21.51, 'environmental': 21.49, 'management': 21.17, 'reduction': 20.84, 'optimal': 20.81, 'range': 20.72, 'hybrid': 20.6, 'renewable': 20.45, 'policy': 20.27, 'driving': 20.12, 'source': 19.74, 'algorithm': 19.74, 'station': 19.3, 'capacity': 18.9, 'design': 18.18, 'storage': 18.18, 'distribution': 18.09, 'process': 17.53, 'dynamic': 17.42, 'application': 17.13, 'generation': 16.39, 'charge': 16.34, 'economic': 16.2, 'adoption': 15.91, 'framework': 15.88, 'conventional': 15.58, 'fleet': 15.45, 'public': 15.43, 'urban': 15.33, 'dioxide': 15.27, 'greenhouse': 15.14, 'sustainable': 14.98, 'parameter': 14.79, 'transition': 14.43, 'behavior': 14.43, 'key': 14.42, 'mobility': 13.83, 'cycle': 13.76, 'supply': 13.61, 'characteristic': 13.47, 'service': 13.38, 'reducing': 13.04, 'engine': 13.01, 'operating': 12.78, 'climate': 12.61, 'cell': 12.29, 'alternative': 12.25, 'planning': 12.2, 'internal': 12.16, 'modeling': 12.13, 'efficient': 12.04, 'mode': 12.01, 'industry': 11.99, 'air': 11.94, 'objective': 11.84, 'combustion': 11.82, 'environment': 11.77, 'production': 11.72, 'effective': 11.53, 'integration': 10.98, 'electrical': 10.74, 'bus': 10.62, 'smart': 10.0}\n"
     ]
    }
   ],
   "source": [
    "# On veut maintenant calculer des poids d'importance des mots pour qu'on puisse attribuer à chaque mot un rayon plus ou moins grand. \n",
    "# On fait une echelle pour avoir des rayons compris entre 10 et 100. \n",
    "def scale(freq, min_freq, max_freq, min_scale=10, max_scale=100):\n",
    "    return min_scale + (freq - min_freq) * (max_scale - min_scale) / (max_freq - min_freq)\n",
    "\n",
    "min_freq = min(dico_filtré.values())\n",
    "max_freq = max(dico_filtré.values())\n",
    "\n",
    "rayon_mots = {\n",
    "    mot: round(scale(freq, min_freq, max_freq), 2)\n",
    "    for mot, freq in dico_filtré.items()\n",
    "}\n",
    "\n",
    "print(rayon_mots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d52f302-b126-438d-af66-7c8f8d8dc09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101, 101)\n",
      "          electric  vehicle  energy  system  study  model  battery  charging  \\\n",
      "electric         0     5249    2970    2936   2721   2667     2454      2469   \n",
      "vehicle       5249        0    2916    2853   2653   2612     2359      2355   \n",
      "energy        2970     2916       0    2220   1699   1672     1551      1346   \n",
      "system        2936     2853    2220       0   1660   1661     1448      1383   \n",
      "study         2721     2653    1699    1660      0   1552     1265      1253   \n",
      "\n",
      "          power  transport  ...  air  objective  combustion  environment  \\\n",
      "electric   2124       1555  ...  486        534         542          493   \n",
      "vehicle    2022       1465  ...  490        521         555          485   \n",
      "energy     1669       1312  ...  333        378         321          352   \n",
      "system     1679       1191  ...  324        356         226          326   \n",
      "study      1078       1059  ...  281        302         302          280   \n",
      "\n",
      "          production  effective  integration  electrical  bus  smart  \n",
      "electric         435        510          471         412  474    456  \n",
      "vehicle          429        495          461         386  372    440  \n",
      "energy           406        310          404         350  302    360  \n",
      "system           295        312          411         352  307    329  \n",
      "study            293        297          262         219  263    238  \n",
      "\n",
      "[5 rows x 101 columns]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import itertools\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "tous_mots = list(dico_filtré)\n",
    "\n",
    "cooc_matrice = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "# On parcourt chaque sous-liste de mots (chaque titre)\n",
    "for mots in L:\n",
    "    mots_filtres = [m for m in set(mots) if m in tous_mots] \n",
    "    for w1, w2 in itertools.combinations(mots_filtres, 2):\n",
    "        cooc_matrice[w1][w2] += 1\n",
    "        cooc_matrice[w2][w1] += 1  #comme on aura une matrice symétrique, on essaie de réduire la complexité en ne parcourant pas deux fois\n",
    "        \n",
    "df_cooc = pd.DataFrame(cooc_matrice, index=tous_mots, columns=tous_mots).fillna(0).astype(int)\n",
    "\n",
    "\n",
    "print(df_cooc.shape)  \n",
    "print(df_cooc.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f93d225f-6f45-466e-aa6d-2aa0e154967b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116 liens trouvés avec cooccurrence > 1000\n",
      "[('electric', 'vehicle'), ('electric', 'energy'), ('electric', 'system'), ('electric', 'study'), ('electric', 'model'), ('electric', 'battery'), ('electric', 'charging'), ('electric', 'power'), ('electric', 'transport'), ('electric', 'electrification'), ('electric', 'emission'), ('electric', 'cost'), ('electric', 'analysis'), ('electric', 'impact'), ('electric', 'demand'), ('electric', 'technology'), ('electric', 'method'), ('electric', 'strategy'), ('electric', 'performance'), ('electric', 'approach'), ('electric', 'data'), ('electric', 'fuel'), ('electric', 'simulation'), ('electric', 'electricity'), ('electric', 'carbon'), ('electric', 'reduce'), ('electric', 'network'), ('electric', 'transportation'), ('electric', 'research'), ('electric', 'solution'), ('electric', 'operation'), ('electric', 'consumption'), ('electric', 'optimization'), ('electric', 'grid'), ('electric', 'infrastructure'), ('electric', 'management'), ('electric', 'optimal'), ('electric', 'hybrid'), ('vehicle', 'energy'), ('vehicle', 'system'), ('vehicle', 'study'), ('vehicle', 'model'), ('vehicle', 'battery'), ('vehicle', 'charging'), ('vehicle', 'power'), ('vehicle', 'transport'), ('vehicle', 'electrification'), ('vehicle', 'emission'), ('vehicle', 'cost'), ('vehicle', 'analysis'), ('vehicle', 'impact'), ('vehicle', 'demand'), ('vehicle', 'technology'), ('vehicle', 'method'), ('vehicle', 'strategy'), ('vehicle', 'performance'), ('vehicle', 'approach'), ('vehicle', 'data'), ('vehicle', 'fuel'), ('vehicle', 'simulation'), ('vehicle', 'electricity'), ('vehicle', 'carbon'), ('vehicle', 'reduce'), ('vehicle', 'network'), ('vehicle', 'transportation'), ('vehicle', 'research'), ('vehicle', 'solution'), ('vehicle', 'consumption'), ('vehicle', 'optimization'), ('vehicle', 'grid'), ('vehicle', 'infrastructure'), ('vehicle', 'management'), ('vehicle', 'hybrid'), ('vehicle', 'driving'), ('energy', 'system'), ('energy', 'study'), ('energy', 'model'), ('energy', 'battery'), ('energy', 'charging'), ('energy', 'power'), ('energy', 'transport'), ('energy', 'electrification'), ('energy', 'emission'), ('energy', 'cost'), ('energy', 'analysis'), ('energy', 'impact'), ('energy', 'demand'), ('energy', 'technology'), ('energy', 'electricity'), ('energy', 'consumption'), ('energy', 'renewable'), ('system', 'study'), ('system', 'model'), ('system', 'battery'), ('system', 'charging'), ('system', 'power'), ('system', 'transport'), ('system', 'electrification'), ('system', 'cost'), ('system', 'demand'), ('study', 'model'), ('study', 'battery'), ('study', 'charging'), ('study', 'power'), ('study', 'transport'), ('study', 'emission'), ('study', 'analysis'), ('model', 'battery'), ('model', 'charging'), ('model', 'power'), ('model', 'cost'), ('battery', 'charging'), ('battery', 'power'), ('charging', 'power'), ('transport', 'electrification'), ('emission', 'carbon')]\n"
     ]
    }
   ],
   "source": [
    "### Liens entre les bulles de mots \n",
    "\n",
    "liens= []\n",
    "\n",
    "for a, b in itertools.combinations(df_cooc.columns, 2):\n",
    "    if df_cooc.loc[a, b] > 1000:  # on choisi de garder que les mots que reviennent ensemble de les titres plus de 1000 fois.\n",
    "        liens.append((a, b))\n",
    "\n",
    "print(f\"{len(liens)} liens trouvés avec cooccurrence > 1000\")\n",
    "print(liens)  # aperçu des premières paires\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46688bb7-db6e-47d2-a2e4-aca54a6b9cd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8da11f4b-8ea9-4eb8-9499-69c825d28f8d",
   "metadata": {},
   "source": [
    "Idées à ce stade : enlever tous les mots qui n'ont pas de liens avec les autres parces qu'ils servent à rien en gros.\n",
    "\n",
    "\n",
    "Ne faire apparaitre les lies de chaque mot que lorsqu'on clique dessus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b878431-8bd9-460d-b156-bf5aded0c69b",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1938022865.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[20], line 3\u001b[1;36m\u001b[0m\n\u001b[1;33m    http -F https://Bob:hiccup@ollama-sam.inria.fr/api/tags | jq '.models.[].name'\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import http\n",
    "\n",
    "http -F https://Bob:hiccup@ollama-sam.inria.fr/api/tags | jq '.models.[].name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd492e6c-e0e7-4151-a57e-7424b536ec7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7256c481-8751-448a-8273-e9e5154bb75e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "HTTPConnectionPool(host='ollama.pl.sophia.inria.fr', port=8080): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001FA8D642300>: Failed to establish a new connection: [WinError 10061] Aucune connexion n’a pu être établie car l’ordinateur cible l’a expressément refusée'))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\ewenm\\miniconda3\\Lib\\site-packages\\urllib3\\connection.py:196\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 196\u001b[0m     sock \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\ewenm\\miniconda3\\Lib\\site-packages\\urllib3\\util\\connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ewenm\\miniconda3\\Lib\\site-packages\\urllib3\\util\\connection.py:73\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     72\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[1;32m---> 73\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[1;31mConnectionRefusedError\u001b[0m: [WinError 10061] Aucune connexion n’a pu être établie car l’ordinateur cible l’a expressément refusée",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\ewenm\\miniconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ewenm\\miniconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:495\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 495\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43menforce_content_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menforce_content_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[38;5;66;03m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;66;03m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;66;03m# With this behaviour, the received response is still readable.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ewenm\\miniconda3\\Lib\\site-packages\\urllib3\\connection.py:398\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers, chunked, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mputheader(header, value)\n\u001b[1;32m--> 398\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    400\u001b[0m \u001b[38;5;66;03m# If we're given a body we start sending that in chunks.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ewenm\\miniconda3\\Lib\\http\\client.py:1331\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[1;32m-> 1331\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ewenm\\miniconda3\\Lib\\http\\client.py:1091\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1090\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[1;32m-> 1091\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1093\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1094\u001b[0m \n\u001b[0;32m   1095\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ewenm\\miniconda3\\Lib\\http\\client.py:1035\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1034\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[1;32m-> 1035\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ewenm\\miniconda3\\Lib\\site-packages\\urllib3\\connection.py:236\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 236\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tunnel_host:\n\u001b[0;32m    238\u001b[0m         \u001b[38;5;66;03m# If we're tunneling it means we're connected to our proxy.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ewenm\\miniconda3\\Lib\\site-packages\\urllib3\\connection.py:211\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 211\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NewConnectionError(\n\u001b[0;32m    212\u001b[0m         \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to establish a new connection: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    213\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;66;03m# Audit hooks are only available in Python 3.8+\u001b[39;00m\n",
      "\u001b[1;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x000001FA8D642300>: Failed to establish a new connection: [WinError 10061] Aucune connexion n’a pu être établie car l’ordinateur cible l’a expressément refusée",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\ewenm\\miniconda3\\Lib\\site-packages\\requests\\adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\ewenm\\miniconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:843\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    841\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[1;32m--> 843\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    844\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    845\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    846\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[1;32mc:\\Users\\ewenm\\miniconda3\\Lib\\site-packages\\urllib3\\util\\retry.py:519\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    518\u001b[0m     reason \u001b[38;5;241m=\u001b[39m error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause)\n\u001b[1;32m--> 519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mreason\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    521\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='ollama.pl.sophia.inria.fr', port=8080): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001FA8D642300>: Failed to establish a new connection: [WinError 10061] Aucune connexion n’a pu être établie car l’ordinateur cible l’a expressément refusée'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttp://ollama.pl.sophia.inria.fr:8080/api/tags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ewenm\\miniconda3\\Lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ewenm\\miniconda3\\Lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ewenm\\miniconda3\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\ewenm\\miniconda3\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\ewenm\\miniconda3\\Lib\\site-packages\\requests\\adapters.py:700\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    696\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, _SSLError):\n\u001b[0;32m    697\u001b[0m         \u001b[38;5;66;03m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[0;32m    698\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m--> 700\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    703\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "\u001b[1;31mConnectionError\u001b[0m: HTTPConnectionPool(host='ollama.pl.sophia.inria.fr', port=8080): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001FA8D642300>: Failed to establish a new connection: [WinError 10061] Aucune connexion n’a pu être établie car l’ordinateur cible l’a expressément refusée'))"
     ]
    }
   ],
   "source": [
    "request = requests.get(\"http://ollama.pl.sophia.inria.fr:8080/api/tags\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c58932-5d14-4a18-b9b2-6ffac2e01e86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "request.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8140b896-672d-4e8c-98b4-28eb04a4257f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qwen2.5-coder:32b\n",
      "qwen2.5-coder:14b\n",
      "qwen2.5-coder:7b\n",
      "codellama:13b\n",
      "starcoder2:latest\n",
      "vicuna:latest\n",
      "starcoder2:instruct\n",
      "sqlcoder:7b\n",
      "starcoder2:15b\n",
      "qwen:7b\n",
      "qwen:32b\n",
      "qwen2.5:32b\n",
      "openchat:7b\n",
      "nous-hermes2-mixtral:8x7b\n",
      "nomic-embed-text:137m-v1.5-fp16\n",
      "moondream:latest\n",
      "mxbai-embed-large:335m-v1-fp16\n",
      "mistral:7b\n",
      "mixtral:8x7b\n",
      "mistral-large:123b\n",
      "mixtral:8x22b\n",
      "llava:34b-v1.6\n",
      "llava:v1.6\n",
      "llava:13b-v1.6\n",
      "llama3:8b\n",
      "llama3.1:8b\n",
      "llama2:13b\n",
      "llama2:latest\n",
      "llama2:70b\n",
      "gemma:7b-instruct\n",
      "gemma2:9b\n",
      "gemma2:27b\n",
      "gemma2:2b\n",
      "falcon:7b-instruct\n",
      "deepseek-coder:6.7b\n",
      "deepseek-coder-v2:16b\n",
      "falcon:40b\n",
      "deepseek-coder:1.3b\n",
      "codestral:22b\n",
      "all-minilm:33m-l12-v2-fp16\n",
      "bespoke-minicheck:7b\n",
      "llama2:7b\n",
      "all-minilm:22m-l6-v2-fp16\n",
      "deepseek-r1:32b\n",
      "llama3.3:70b\n",
      "deepseek-r1:7b\n",
      "deepseek-r1:14b\n",
      "granite3.2-vision:2b-q4_K_M\n",
      "llama3.2:3b-instruct-q5_K_M\n"
     ]
    }
   ],
   "source": [
    "for n in request.json()['models'] : \n",
    "    print(n['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c04f48-410d-467a-8cf8-d065bc7d14ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://ollama-sam.inria.fr/\"\n",
    "login, passwd = \"Bob\",\"hiccup\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c4b1c5-c913-41d6-a243-147cab8a805b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# request = requests.get(URL + \"api/tags\"), auth = (login, passwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2197209-da84-4eaa-89fa-a3e19c49dd3c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "HTTPConnectionPool(host='ollama.pl.sophia.inria.fr', port=8080): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001FABAC4D7F0>: Failed to establish a new connection: [WinError 10061] Aucune connexion n’a pu être établie car l’ordinateur cible l’a expressément refusée'))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\ewenm\\miniconda3\\Lib\\site-packages\\urllib3\\connection.py:196\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 196\u001b[0m     sock \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\ewenm\\miniconda3\\Lib\\site-packages\\urllib3\\util\\connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ewenm\\miniconda3\\Lib\\site-packages\\urllib3\\util\\connection.py:73\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     72\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[1;32m---> 73\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[1;31mConnectionRefusedError\u001b[0m: [WinError 10061] Aucune connexion n’a pu être établie car l’ordinateur cible l’a expressément refusée",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\ewenm\\miniconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ewenm\\miniconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:495\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 495\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43menforce_content_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menforce_content_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[38;5;66;03m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;66;03m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;66;03m# With this behaviour, the received response is still readable.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ewenm\\miniconda3\\Lib\\site-packages\\urllib3\\connection.py:398\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers, chunked, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mputheader(header, value)\n\u001b[1;32m--> 398\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    400\u001b[0m \u001b[38;5;66;03m# If we're given a body we start sending that in chunks.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ewenm\\miniconda3\\Lib\\http\\client.py:1331\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[1;32m-> 1331\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ewenm\\miniconda3\\Lib\\http\\client.py:1091\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1090\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[1;32m-> 1091\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1093\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1094\u001b[0m \n\u001b[0;32m   1095\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ewenm\\miniconda3\\Lib\\http\\client.py:1035\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1034\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[1;32m-> 1035\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ewenm\\miniconda3\\Lib\\site-packages\\urllib3\\connection.py:236\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 236\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tunnel_host:\n\u001b[0;32m    238\u001b[0m         \u001b[38;5;66;03m# If we're tunneling it means we're connected to our proxy.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ewenm\\miniconda3\\Lib\\site-packages\\urllib3\\connection.py:211\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 211\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NewConnectionError(\n\u001b[0;32m    212\u001b[0m         \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to establish a new connection: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    213\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;66;03m# Audit hooks are only available in Python 3.8+\u001b[39;00m\n",
      "\u001b[1;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x000001FABAC4D7F0>: Failed to establish a new connection: [WinError 10061] Aucune connexion n’a pu être établie car l’ordinateur cible l’a expressément refusée",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\ewenm\\miniconda3\\Lib\\site-packages\\requests\\adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\ewenm\\miniconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:843\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    841\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[1;32m--> 843\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    844\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    845\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    846\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[1;32mc:\\Users\\ewenm\\miniconda3\\Lib\\site-packages\\urllib3\\util\\retry.py:519\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    518\u001b[0m     reason \u001b[38;5;241m=\u001b[39m error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause)\n\u001b[1;32m--> 519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mreason\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    521\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='ollama.pl.sophia.inria.fr', port=8080): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001FABAC4D7F0>: Failed to establish a new connection: [WinError 10061] Aucune connexion n’a pu être établie car l’ordinateur cible l’a expressément refusée'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhi\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmistral:7b\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 6\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttp://ollama.pl.sophia.inria.fr:8080/api/generate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprompt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ewenm\\miniconda3\\Lib\\site-packages\\requests\\api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[1;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \n\u001b[0;32m    106\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ewenm\\miniconda3\\Lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ewenm\\miniconda3\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\ewenm\\miniconda3\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\ewenm\\miniconda3\\Lib\\site-packages\\requests\\adapters.py:700\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    696\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, _SSLError):\n\u001b[0;32m    697\u001b[0m         \u001b[38;5;66;03m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[0;32m    698\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m--> 700\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    703\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "\u001b[1;31mConnectionError\u001b[0m: HTTPConnectionPool(host='ollama.pl.sophia.inria.fr', port=8080): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001FABAC4D7F0>: Failed to establish a new connection: [WinError 10061] Aucune connexion n’a pu être établie car l’ordinateur cible l’a expressément refusée'))"
     ]
    }
   ],
   "source": [
    "# pour envoyer une requete prompt : \n",
    "\n",
    "prompt = \"hi\"\n",
    "model = \"mistral:7b\"\n",
    "\n",
    "request = requests.post(\"http://ollama.pl.sophia.inria.fr:8080/api/generate\", data = {'prompt' :prompt , 'model' :model})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b977f9-4ff2-4e38-8d9e-1c6e74409fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = request.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2faf30d5-0211-4d0f-ae58-fc0cb539a51a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"error\":\"invalid character \\'p\\' looking for beginning of value\"}'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9940653f-a096-4eff-a481-dc754f433d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-md==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.8.0/en_core_web_md-3.8.0-py3-none-any.whl (33.5 MB)\n",
      "     ---------------------------------------- 0.0/33.5 MB ? eta -:--:--\n",
      "     --- ------------------------------------ 2.9/33.5 MB 16.8 MB/s eta 0:00:02\n",
      "     ------- -------------------------------- 6.3/33.5 MB 15.5 MB/s eta 0:00:02\n",
      "     ----------- --------------------------- 10.2/33.5 MB 16.4 MB/s eta 0:00:02\n",
      "     --------------- ----------------------- 13.6/33.5 MB 16.5 MB/s eta 0:00:02\n",
      "     --------------------- ----------------- 18.4/33.5 MB 17.5 MB/s eta 0:00:01\n",
      "     --------------------------- ----------- 23.3/33.5 MB 18.7 MB/s eta 0:00:01\n",
      "     -------------------------------- ------ 28.3/33.5 MB 19.5 MB/s eta 0:00:01\n",
      "     ------------------------------------- - 32.5/33.5 MB 19.3 MB/s eta 0:00:01\n",
      "     --------------------------------------- 33.5/33.5 MB 18.8 MB/s eta 0:00:00\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_md')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d3cfcaa1-0c66-439a-8586-252bdc5ef191",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-9 (_readerthread):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ewenm\\miniconda3\\Lib\\threading.py\", line 1073, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\ewenm\\miniconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"c:\\Users\\ewenm\\miniconda3\\Lib\\threading.py\", line 1010, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\ewenm\\miniconda3\\Lib\\subprocess.py\", line 1599, in _readerthread\n",
      "    buffer.append(fh.read())\n",
      "                  ^^^^^^^^^\n",
      "  File \"<frozen codecs>\", line 322, in decode\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0x82 in position 110: invalid start byte\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: ['operation', 'process', 'application'], 1: ['study', 'model', 'emission', 'analysis', 'impact', 'method', 'approach', 'data', 'simulation', 'research', 'environmental', 'station', 'design', 'dynamic', 'framework', 'parameter', 'characteristic', 'alternative', 'modeling', 'objective', 'production', 'effective', 'smart'], 2: ['strategy', 'range', 'driving', 'adoption', 'conventional', 'behavior', 'bus'], 3: ['demand', 'reduce', 'development', 'transition', 'cycle', 'climate', 'cell'], 4: ['electric', 'system', 'power', 'transport', 'technology', 'performance', 'network', 'solution', 'consumption', 'optimization', 'efficiency', 'infrastructure', 'reduction', 'optimal', 'algorithm', 'capacity', 'storage', 'distribution', 'generation', 'mobility', 'supply', 'reducing', 'engine', 'operating', 'internal', 'efficient', 'mode', 'air', 'environment', 'integration', 'electrical'], 5: ['energy', 'electrification', 'fuel', 'electricity', 'carbon', 'grid', 'hybrid', 'renewable', 'source', 'dioxide', 'greenhouse', 'sustainable', 'industry', 'combustion'], 6: ['vehicle', 'battery', 'charging', 'cost', 'sector', 'transportation', 'management', 'policy', 'charge', 'economic', 'fleet', 'public', 'urban', 'key', 'service', 'planning']}\n"
     ]
    }
   ],
   "source": [
    "# on essaie de faire des clusters sémantiques \n",
    "import spacy\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "words = list(dico_filtré.keys())\n",
    "vectors = np.array([nlp(w).vector for w in words])\n",
    "\n",
    "kmeans = KMeans(n_clusters=7, random_state=0).fit(vectors)\n",
    "clusters = {i: [] for i in range(7)}\n",
    "for i, label in enumerate(kmeans.labels_):\n",
    "    clusters[label].append(words[i])\n",
    "\n",
    "print(clusters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f9c1848f",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = df['COUNTRY'].sort_values().unique()\n",
    "years = df['YEAR'].sort_values().unique()\n",
    "countries = np.append(countries, ['ALL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "23ecf159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['electric', 'vehicle', 'energy', 'system', 'study', 'model',\n",
       "       'battery', 'charging', 'power', 'transport', 'electrification',\n",
       "       'emission', 'cost', 'analysis', 'impact', 'demand', 'technology',\n",
       "       'method', 'strategy', 'performance', 'approach', 'data', 'fuel',\n",
       "       'simulation', 'electricity', 'carbon', 'reduce', 'network',\n",
       "       'sector', 'transportation', 'research', 'solution', 'operation',\n",
       "       'consumption', 'optimization', 'grid', 'efficiency',\n",
       "       'infrastructure', 'development', 'environmental', 'management',\n",
       "       'reduction', 'optimal', 'range', 'hybrid', 'renewable', 'policy',\n",
       "       'driving', 'source', 'algorithm', 'station', 'capacity', 'design',\n",
       "       'storage', 'distribution', 'process', 'dynamic', 'application',\n",
       "       'generation', 'charge', 'economic', 'adoption', 'framework',\n",
       "       'conventional', 'fleet', 'public', 'urban', 'dioxide',\n",
       "       'greenhouse', 'sustainable', 'parameter', 'transition', 'behavior',\n",
       "       'key', 'mobility', 'cycle', 'supply', 'characteristic', 'service',\n",
       "       'reducing', 'engine', 'operating', 'climate', 'cell',\n",
       "       'alternative', 'planning', 'internal', 'modeling', 'efficient',\n",
       "       'mode', 'industry', 'air', 'objective', 'combustion',\n",
       "       'environment', 'production', 'effective', 'integration',\n",
       "       'electrical', 'bus', 'smart'], dtype='<U15')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords = np.array(list(dico_filtré.keys()))\n",
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "928aedb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "etiquettes_data = df.iloc[:, [2,6,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28]]  # à partir de la colonne 12, on prend tous les mots clés des études scientifiques "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4fd23098",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keywords_per_country(COUNTRY) : \n",
    "    etiquettes_series = pd.Series(etiquettes_data[etiquettes_data[\"COUNTRY\"] == COUNTRY].iloc[:,2:].values.ravel())\n",
    "    etiquettes_series = etiquettes_series.dropna().astype(str).str.strip().str.lower() \n",
    "    etiquettes_series = etiquettes_series[(etiquettes_series!='0')]\n",
    "    keywords_unfiltered = list(etiquettes_series)\n",
    "    return keywords_unfiltered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b08385eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keywords_per_year(YEAR) : \n",
    "    etiquettes_series = pd.Series(etiquettes_data[etiquettes_data[\"YEAR\"] == YEAR].iloc[:,2:].values.ravel())\n",
    "    etiquettes_series = etiquettes_series.dropna().astype(str).str.strip().str.lower() \n",
    "    etiquettes_series = etiquettes_series[(etiquettes_series!='0')]\n",
    "    keywords_unfiltered = list(etiquettes_series)\n",
    "    #keywords_filtered = [word for word in keywords_unfiltered if word in keywords]\n",
    "    return keywords_unfiltered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5337aa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keywords_per_country_year(COUNTRY, YEAR) : \n",
    "    etiquettes_series = pd.Series(etiquettes_data[(etiquettes_data[\"YEAR\"] == YEAR)&(etiquettes_data[\"COUNTRY\"] == COUNTRY)].iloc[:,2:].values.ravel())\n",
    "    etiquettes_series = etiquettes_series.dropna().astype(str).str.strip().str.lower() \n",
    "    etiquettes_series = etiquettes_series[(etiquettes_series!='0')]\n",
    "    keywords_unfiltered = list(etiquettes_series)\n",
    "    #keywords_filtered = [word for word in keywords_unfiltered if word in keywords]\n",
    "    return list(set(keywords_unfiltered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "94bda1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keywords_split(keywords_unfiltered) :\n",
    "    retour = []\n",
    "    for keyword in keywords_unfiltered :\n",
    "        retour += keyword.split()\n",
    "    return retour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8ac556c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtered_keywords(unfiltered) : \n",
    "    return list(filter(lambda x: x in keywords, unfiltered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "789c55a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sans_doublons(liste) : \n",
    "    dico = {}\n",
    "    retour = []\n",
    "    for mot in liste : \n",
    "        if not mot in dico :\n",
    "            dico[mot] = 0\n",
    "            retour.append(mot)\n",
    "    return retour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fe6745b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def country(COUNTRY) : \n",
    "    return sans_doublons(filtered_keywords(keywords_split(keywords_per_country(COUNTRY))))\n",
    "\n",
    "def year(YEAR) : \n",
    "    return sans_doublons(filtered_keywords(keywords_split(keywords_per_year(YEAR))))\n",
    "\n",
    "def country_and_year(COUNTRY, YEAR):\n",
    "    return sans_doublons(filtered_keywords(keywords_split(keywords_per_country_year(COUNTRY, YEAR))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c892e8-50f3-481f-8936-32c60464b46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "519 liens trouvés avec cooccurrence > 1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x252d6199760>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dash\n",
    "from dash import html, dcc, Input, Output,State\n",
    "import plotly.graph_objects as go\n",
    "import networkx as nx\n",
    "import random\n",
    "\n",
    "### On choisi le nombre de liens qu'on veut entre les mots \n",
    "liens= []\n",
    "\n",
    "for a, b in itertools.combinations(df_cooc.columns, 2):\n",
    "    if df_cooc.loc[a, b] > 500:  # on choisi de garder que les mots que reviennent ensemble de les titres plus de tant de fois.\n",
    "        liens.append((a, b))\n",
    "\n",
    "print(f\"{len(liens)} liens trouvés avec cooccurrence > 1000\")\n",
    "\n",
    "\n",
    "# Couleurs des clusters de mots sémantiques\n",
    "color_palette = ['red', 'orange', 'green', 'blue', 'purple', 'teal', 'brown']\n",
    "node_color_map = {}\n",
    "node_cluster_map = {}\n",
    "for cluster_id, mots in clusters.items():\n",
    "    for mot in mots:\n",
    "        node_color_map[mot] = color_palette[cluster_id % len(color_palette)]\n",
    "        node_cluster_map[mot] = cluster_id\n",
    "\n",
    "##### GRAPHE \n",
    "#Cette partie permet de créer le graphe et d'ajouter des noeuds (nodes)  avec leurs tailles, et les liens (edges) entre les noeuds\n",
    "G = nx.Graph()\n",
    "for mot, poids in dico_filtré.items(): #on crée un noeud avec un mot clé de dico_filtré et sa taille\n",
    "    G.add_node(mot)\n",
    "    G.nodes[mot]['size'] = poids\n",
    "G.add_edges_from(liens)\n",
    "\n",
    "for node in G.nodes():\n",
    "    if 'size' not in G.nodes[node]:\n",
    "        G.nodes[node]['size'] = min(dico_filtré.values())\n",
    "# Test pour vérifier que tous les noeuds ont une taille, sinon on lui attribue le min des poids (valeurs du dictionnaire)\n",
    "\n",
    "# On commence par choisir des endroits distincts aléatoirement pour les différents foyers des clusters \n",
    "cluster_pos = {i: (random.uniform(-1, 1), random.uniform(-1, 1)) for i in clusters.keys()}\n",
    "initial_pos = {mot: cluster_pos.get(node_cluster_map.get(mot, -1), (0, 0)) for mot in G.nodes()}\n",
    "\n",
    "cluster_nodes = {i: [] for i in clusters.keys()}\n",
    "for node in G.nodes():\n",
    "    cluster = node_cluster_map.get(node, -1) # on récupère le cluster du noeud, ou -1 s'il n'est pas dans un cluster\n",
    "    cluster_nodes[cluster].append(node) # on ajoute le noeud a la structure cluster correspondante\n",
    "\n",
    "# On calcule les positions des noeuds manuellement\n",
    "manual_pos = {}\n",
    "for cluster_id, nodes in cluster_nodes.items():\n",
    "    unconnected = [n for n in nodes if G.degree[n] == 0] # on récupère les noeuds non connectés\n",
    "    angle_step = 360 / max(len(unconnected), 1) # on fait ceci pour éviter la division par zéro\n",
    "    radius = 0.15 + len(unconnected) * 0.01  # rayon variable\n",
    "    center_x, center_y = cluster_pos.get(cluster_id, (0, 0))\n",
    "    for i, node in enumerate(unconnected): # on parcourt les noeuds non connectés\n",
    "        angle_rad = (angle_step * i) * (3.1416 / 180)\n",
    "        x = center_x + radius * random.uniform(0.9, 1.1) * np.cos(angle_rad)\n",
    "        y = center_y + radius * random.uniform(0.9, 1.1) * np.sin(angle_rad)\n",
    "        manual_pos[node] = (x, y)\n",
    "\n",
    "#on prend les positions initiales et manuelles \n",
    "combined_pos = initial_pos.copy()\n",
    "combined_pos.update(manual_pos)\n",
    "\n",
    "\n",
    "pos = nx.spring_layout(G, pos=combined_pos, fixed=manual_pos.keys(), seed=42, k=0.4) # On utilise spring_layout pour ajuster les positions des noeuds en fonction des liens et des positions manuelles, avec une technique de minimisation de l'énergie, si on compare les distances à des coefficients de ressorts\n",
    "\n",
    "app = dash.Dash(__name__)  #INTERFACE DASH\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"Graphe sémantique par clusters\"),      #Titre du graphe\n",
    "    html.P(\"Select country:\"),                      #Section pour choisir le pays\n",
    "        dcc.Dropdown(\n",
    "            id=\"dropdown\",\n",
    "            options= countries, # Liste des pays (cf ci dessus)\n",
    "            value=\"ALBANIA\",    # Valeur par défaut\n",
    "            clearable=False,    # On ne peut pas effacer la valeur par défaut\n",
    "        ),\n",
    "    html.P(\"Select Year :\"),    #Section pour choisir l'année\n",
    "    dcc.Dropdown(\n",
    "        id=\"year-dropdown\", \n",
    "        options= years, # Liste des années (cf ci dessus)\n",
    "        value=\"2020\",  # Valeur par défaut\n",
    "        clearable=False,\n",
    "    ),\n",
    "    dcc.Graph(id=\"graph\")\n",
    "])\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"graph\", \"figure\"),\n",
    "    Input(\"graph\", \"hoverData\"),\n",
    "    State(\"graph\", \"relayoutData\"),\n",
    "    State(\"dropdown\", \"value\"),\n",
    "    State(\"year-dropdown\", \"value\"),\n",
    ") #On utilise un callback pour mettre à jour le graphe en fonction des interactions de l'utilisateur, hoverData pour le survol des noeuds, relayoutData pour les changements de zoom ou de position, et les valeurs des dropdowns pour le pays et l'année sélectionnés.\n",
    "\n",
    "def update_graph(hoverData, relayoutData, country, year):\n",
    "    if country == \"ALL\":\n",
    "        keywords = keywords_per_year(year)\n",
    "    else:\n",
    "        keywords = country_and_year(country, year)  # On récupère les mots-clés en fonction du pays et de l'année sélectionnés\n",
    "    \n",
    "    # Reconstruire le node_trace\n",
    "    node_x, node_y, node_text, node_size, node_colors = [], [], [], [], []\n",
    "    max_poids = max(dico_filtré.values())\n",
    "    for node in G.nodes():  # On parcourt tous les noeuds du graphe et on récupère les informations (positions, taille...)\n",
    "        x, y = pos[node]\n",
    "        node_x.append(x)\n",
    "        node_y.append(y)\n",
    "        node_text.append(node)\n",
    "        node_size.append(G.nodes[node]['size'] / max_poids * 50 + 10)\n",
    "        node_colors.append(node_color_map.get(node, \"gray\") if node in keywords else \"#888\") \n",
    "        # On utilise la couleur du cluster si le mot est dans les mots-clés, sinon on met une couleur grise (888)\n",
    "    \n",
    "    # On crée le tracé pour les noeuds du graphe\n",
    "    node_trace = go.Scatter(\n",
    "    x=node_x, y=node_y,\n",
    "    mode=\"markers+text\",\n",
    "    text=node_text,\n",
    "    hoverinfo=\"text\",\n",
    "    customdata=node_text,    #customdata est nécessaire ensuite pour ne pas renvoyer un message d'erreur quand on survole un noeud (ce qui est le cas si on utilise que text)\n",
    "    marker=dict(\n",
    "        color=node_colors,\n",
    "        size=node_size,\n",
    "        line_width=2\n",
    "    ),\n",
    "    textposition=\"top center\" # on place le texte au dessus au milieu par rapport au noeud\n",
    "    )\n",
    "\n",
    "    fig = go.Figure(\n",
    "            data=[node_trace],\n",
    "            layout=go.Layout(\n",
    "                showlegend=False,\n",
    "                hovermode=\"closest\",\n",
    "                margin=dict(b=20, l=5, r=5, t=40),\n",
    "                xaxis=dict(showgrid=False, zeroline=False),\n",
    "                yaxis=dict(showgrid=False, zeroline=False),\n",
    "            ),\n",
    "        ) \n",
    "    #On récupère les données de la figure à tracer (le tracé des noeuds, les axes...)\n",
    "    \n",
    "    if relayoutData: #cette partie concerne le zoom et adapte l'échelle des deux axes lorsqu'on zoom\n",
    "        if 'xaxis.range[0]' in relayoutData and 'xaxis.range[1]' in relayoutData: \n",
    "            fig.update_xaxes(range=[\n",
    "                relayoutData['xaxis.range[0]'],\n",
    "                relayoutData['xaxis.range[1]']\n",
    "            ]) \n",
    "        if 'yaxis.range[0]' in relayoutData and 'yaxis.range[1]' in relayoutData:\n",
    "            fig.update_yaxes(range=[\n",
    "                relayoutData['yaxis.range[0]'],\n",
    "                relayoutData['yaxis.range[1]']\n",
    "            ])\n",
    "\n",
    "    if hoverData is None: #si on ne survole pas de noeud, la figure reste identique \n",
    "        return fig \n",
    "\n",
    "    # Récupérer le nœud survolé\n",
    "    try:\n",
    "        node_id = hoverData[\"points\"][0][\"customdata\"] # noeud survolé\n",
    "    except (KeyError, IndexError, TypeError):\n",
    "        # Fallback en cas de structure inattendue\n",
    "        return dash.no_update\n",
    "\n",
    "    # Arêtes liées à ce nœud\n",
    "    filtered_edges = [e for e in G.edges() if node_id in e]\n",
    "\n",
    "    # Générer uniquement les segments des arêtes concernées\n",
    "    edge_x, edge_y = [], []\n",
    "    for edge in filtered_edges:\n",
    "        x0, y0 = pos[edge[0]]\n",
    "        x1, y1 = pos[edge[1]]\n",
    "        edge_x += [x0, x1, None] \n",
    "        edge_y += [y0, y1, None] \n",
    "\n",
    "    #Cette partie permet de tracer les arêtes reliées au noeud seleccioné\n",
    "    edge_trace = go.Scatter(\n",
    "        x=edge_x,\n",
    "        y=edge_y,\n",
    "        line=dict(width=2, color=\"#888\"),\n",
    "        hoverinfo=\"none\",\n",
    "        mode=\"lines\",\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(edge_trace)   #la figure intègre le tracé des arêtes qui sont donc ajoutées et apparaissent sur le graphe\n",
    "\n",
    "    return fig \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True)     #intructions pour faire tourner l'app"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
